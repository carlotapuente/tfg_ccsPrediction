{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d36739ee-a766-4591-9154-1ec49fb3f65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.0.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision==0.15.1 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torchvision==0.15.1) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torchvision==0.15.1) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torchvision==0.15.1) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.1) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.0.0 torchvision==0.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729565be-5bab-45de-b2fb-df4bac1f3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install d2l==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec93e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Molecule Name Molecular Formula  \\\n",
      "0   3-[3-(2,3-dihydroindol-1-yl)propyl]-1-[(4-fluo...        C19H22FN3O   \n",
      "1   3-{[1,1'-biphenyl]-4-ylmethylidene}-6-fluoro-2...        C22H15FO3S   \n",
      "2   1-{[3-(4-methoxyphenyl)-1,2,4-oxadiazol-5-yl]m...        C25H28N4O3   \n",
      "3   3-[2-oxo-2-(4-phenylmethanesulfonylpiperazin-1...       C22H30N4O5S   \n",
      "4   2-{[1,1'-biphenyl]-2-ylamino}-1-(morpholin-4-y...        C18H20N2O2   \n",
      "5   1-(2-{[1,1'-biphenyl]-2-ylamino}acetyl)imidazo...        C17H17N3O2   \n",
      "6   N-(2,3-dihydro-1,4-benzodioxin-6-yl)-2-{[1-(4-...      C23H21N5O3S2   \n",
      "7                                              Tm_322                     \n",
      "8   N-[(1-benzyl-3,5-dimethylpyrazol-4-yl)methyl]-...       C24H25N5O2S   \n",
      "9   N-{[1,1'-biphenyl]-4-yl}-2-(2-oxoquinoxalin-1-...        C22H17N3O2   \n",
      "10                                             Tm_322                     \n",
      "11  N-(4-ethoxyphenyl)-2-{2-[5-(4-methylphenyl)-1,...        C25H24N6O3   \n",
      "12                                             Tm_622                     \n",
      "14  N-cyclohexyl-N-ethyl-4-(piperidine-1-sulfonyl)...      C19H30N2O4S2   \n",
      "15  [(6-amino-1-benzyl-2,4-dioxo-3H-pyrimidin-5-yl...       C25H26N4O7S   \n",
      "16  3-[(2H-1,3-benzodioxol-5-ylmethyl)sulfanyl]-4-...       C21H17N3O3S   \n",
      "17  N-[(1S)-1-(1H-1,3-benzodiazol-2-yl)-2-phenylet...      C26H28N4O3S2   \n",
      "18    4-methoxy-N-[4-(piperidin-1-yl)phenyl]benzamide        C19H22N2O2   \n",
      "19  1-[4-(4-isopropylbenzoyl)piperazin-1-yl]-3-phe...        C23H26N2O2   \n",
      "\n",
      "    METLIN ID Precursor Adduct    CCS1    CCS2    CCS3  CCS_AVG  % CV  \\\n",
      "0   1181481.0    328.1820[M+H]  176.63  176.63  176.63   176.63     0   \n",
      "1   1191359.0    379.0799[M+H]  192.26  192.26  192.26   192.26     0   \n",
      "2   1228206.0    433.2234[M+H]  211.12  211.12  211.12   211.12     0   \n",
      "3   1176932.0    463.2010[M+H]  204.22  204.22  204.22   204.22     0   \n",
      "4   1183857.0    297.1598[M+H]  174.47  174.47  174.47   174.47     0   \n",
      "5   1177044.0    296.1394[M+H]  170.17  170.17  170.17   170.17     0   \n",
      "6   1184006.0    480.1159[M+H]  215.24  215.24  215.24   215.24     0   \n",
      "7         NaN    322.0481[M+H]  154.22  154.22  154.22   154.22     0   \n",
      "8   1205024.0    448.1802[M+H]  198.49  198.49  198.49   198.49     0   \n",
      "9   1184329.0    356.1394[M+H]  195.75  195.75  195.75   195.75     0   \n",
      "10        NaN    322.0481[M+H]  154.81  154.81  154.81   154.81     0   \n",
      "11  1226735.0    457.1983[M+H]  214.97  214.97  214.97   214.97     0   \n",
      "12        NaN    622.0290[M+H]  205.00  205.00  205.00   205.00     0   \n",
      "14  1202359.0    415.1720[M+H]  204.53  204.53  204.53   204.53     0   \n",
      "15  1184004.0    527.1595[M+H]  211.86  211.86  211.86   211.86     0   \n",
      "16  1198192.0    392.1063[M+H]  189.34  189.34  189.34   189.34     0   \n",
      "17  1174820.0    509.1676[M+H]  214.83  214.83  214.83   214.83     0   \n",
      "18  1177187.0    311.1754[M+H]  185.40  185.40  185.40   185.40     0   \n",
      "19  1172634.0    363.2067[M+H]  202.66  202.66  202.66   202.66     0   \n",
      "\n",
      "         m/z  ... V2205  V2206  V2207 V2208  V2209  V2210  V2211 V2212 V2213  \\\n",
      "0   328.1820  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "1   379.0799  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0   \n",
      "2   433.2234  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "3   463.2010  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "4   297.1598  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "5   296.1394  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "6   480.1159  ...   0.0    0.0    0.0   1.0    0.0    0.0    0.0   0.0   1.0   \n",
      "7   322.0481  ...   NaN    NaN    NaN   NaN    NaN    NaN    NaN   NaN   NaN   \n",
      "8   448.1802  ...   0.0    0.0    0.0   1.0    0.0    0.0    0.0   0.0   1.0   \n",
      "9   356.1394  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "10  322.0481  ...   NaN    NaN    NaN   NaN    NaN    NaN    NaN   NaN   NaN   \n",
      "11  457.1983  ...   0.0    0.0    0.0   0.0    1.0    0.0    0.0   0.0   1.0   \n",
      "12  622.0290  ...   NaN    NaN    NaN   NaN    NaN    NaN    NaN   NaN   NaN   \n",
      "14  415.1720  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "15  527.1595  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "16  392.1063  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0   \n",
      "17  509.1676  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "18  311.1754  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "19  363.2067  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "\n",
      "   V2214  \n",
      "0    0.0  \n",
      "1    0.0  \n",
      "2    1.0  \n",
      "3    0.0  \n",
      "4    0.0  \n",
      "5    0.0  \n",
      "6    1.0  \n",
      "7    NaN  \n",
      "8    1.0  \n",
      "9    0.0  \n",
      "10   NaN  \n",
      "11   1.0  \n",
      "12   NaN  \n",
      "14   0.0  \n",
      "15   0.0  \n",
      "16   1.0  \n",
      "17   1.0  \n",
      "18   0.0  \n",
      "19   0.0  \n",
      "\n",
      "[19 rows x 2235 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = 'METLIN_CCS_vectorfingerprintsVectorized.csv'\n",
    "\n",
    "column_name = 'Dimer.1'\n",
    "value_to_filter = 'Monomer'\n",
    "\n",
    "original_data = pd.read_csv(csv_file_path, nrows = 20)\n",
    "\n",
    "data = original_data[original_data['Dimer.1'] == 'Monomer']\n",
    "\n",
    "# Save the filtered DataFrame back to the CSV file, overwriting the original file\n",
    "data.to_csv('METLIN_CCS_vectorfingerprintsVectorized_filtered.csv', index=False)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d342aae-c875-435b-bd3d-e00fbfa44d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [2.]\n",
      " [0.]]\n",
      "0     [1.0]\n",
      "1     [1.0]\n",
      "2     [1.0]\n",
      "3     [1.0]\n",
      "4     [1.0]\n",
      "5     [1.0]\n",
      "6     [1.0]\n",
      "7     [1.0]\n",
      "8     [1.0]\n",
      "9     [1.0]\n",
      "10    [1.0]\n",
      "11    [1.0]\n",
      "12    [1.0]\n",
      "14    [1.0]\n",
      "15    [1.0]\n",
      "16    [1.0]\n",
      "17    [1.0]\n",
      "18    [1.0]\n",
      "19    [1.0]\n",
      "Name: Adduct, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "adducts = data.iloc[:, 10]\n",
    "adduct_types = ['[M+H]', '[M+Na]', '[2M+H]']\n",
    "encoder = OrdinalEncoder()\n",
    "adducts_2d = np.array(adduct_types).reshape(-1, 1)\n",
    "encoded_adducts = encoder.fit_transform(adducts_2d)\n",
    "print(encoded_adducts)\n",
    "\n",
    "adducts_map = {'[M+H]': encoded_adducts[0], '[M+Na]': encoded_adducts[1], '[2M+H]': encoded_adducts[2]}\n",
    "mapped_adducts = adducts.map(adducts_map)\n",
    "print(mapped_adducts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228fe820-2eb2-4e4e-b3f1-620e1a4246b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 100])\n",
      "tensor([[328.1820,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [379.0799,   1.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [433.2234,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        ...,\n",
      "        [509.1676,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [311.1754,   1.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [363.2067,   1.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([19])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# adduct = torch.tensor(mapped_adducts)\n",
    "fingerprints = torch.tensor(data.iloc[:, 21:121].to_numpy(dtype=int))\n",
    "# fingerprints = data.iloc[:, 21:121]\n",
    "print(fingerprints.shape)\n",
    "# fingerprints = torch.tensor(data.iloc[:, 21:2235].to_numpy(dtype=int))\n",
    "mz = torch.tensor(data.iloc[:, 9].to_numpy(dtype=float))\n",
    "# mz = data.iloc[:, 9]\n",
    " \n",
    "# dataset_tensor = X    \n",
    "# X = torch.cat((mz.unsqueeze(1), fingerprints, adduct), dim=1) \n",
    "X = torch.cat((mz.unsqueeze(1), fingerprints), dim=1)\n",
    "# fingerprints.insert(0, 'm/z', mz)\n",
    "# fingerprints['mz'] = mz\n",
    "# X = fingerprints\n",
    "\n",
    "# X = data.iloc[:, 21:121]\n",
    "# mz.unsqueeze convierte el vector mz de dimension [100] en una matriz de dimensiones [100,1], para poder concatenarlo\n",
    "\n",
    "# target = y\n",
    "y = torch.tensor(data.iloc[:, 7].to_numpy(dtype=float))\n",
    "# y = data.iloc[:, 7].to_numpy()\n",
    "\n",
    "print(X)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Display the name of the active environment\n",
    "print(f\"Active environment: {os.environ['CONDA_DEFAULT_ENV']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49de8157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat idxs [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "train indices tensor([ 1,  2,  4,  8, 12, 14, 15, 16])\n",
      "valid indices tensor([ 3,  6,  7, 11, 13])\n",
      "test indices tensor([ 0,  5,  9, 10, 17, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_20800\\3479867200.py:99: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32)\n",
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_20800\\3479867200.py:99: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 101\u001b[0m\n\u001b[0;32m     97\u001b[0m train_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstd(cont, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     99\u001b[0m continuous_mean_std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([train_mean,train_std])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \n\u001b[1;32m--> 101\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m DataSetCatCon(X_train, y_train, cat_idxs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg\u001b[39m\u001b[38;5;124m'\u001b[39m,continuous_mean_std)\n\u001b[0;32m    102\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m DataLoader(train_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs,'reg', continuous_mean_std)\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# validloader = DataLoader(valid_ds, batch_size=256, shuffle=False,num_workers=4)\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# test_ds = DataSetCatCon(X_test, y_test, cat_idxs,'reg', continuous_mean_std)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# testloader = DataLoader(test_ds, batch_size=256, shuffle=False,num_workers=4)\u001b[39;00m\n",
      "File \u001b[1;32m~\\data_openml.py:110\u001b[0m, in \u001b[0;36mDataSetCatCon.__init__\u001b[1;34m(self, X, Y, cat_cols, task, continuous_mean_std)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, cat_cols,task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m,continuous_mean_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    109\u001b[0m     cat_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(cat_cols)\n\u001b[1;32m--> 110\u001b[0m     X_mask \u001b[38;5;241m=\u001b[39m  X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    111\u001b[0m     X \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    112\u001b[0m     con_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(cat_cols))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "from models import SAINT\n",
    "from data_openml import data_prep_openml,task_dset_ids,DataSetCatCon, data_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from augmentations import embed_data_mask\n",
    "\n",
    "\n",
    "categorical_indicator = [False] + [True] * 100 # faltan los adducts\n",
    "cat_dims = [2] * 100 # 2: fingerprints solo pueden tomar dos valores (binario)\n",
    "cat_dims = np.append(np.array([1]),np.array(cat_dims)).astype(int) #Appending 1 for CLS token, this is later used to generate embeddings.\n",
    "  \n",
    "cat_idxs = list(np.where(np.array(categorical_indicator)==True)[0]) # discrete/categorical features\n",
    "print(\"cat idxs\", cat_idxs)\n",
    "con_idxs = list(set(range(X.size(1))) - set(cat_idxs)) # continuous/numerical features \n",
    "\n",
    "model = SAINT(\n",
    "    categories = tuple(cat_dims), \n",
    "    num_continuous = len(con_idxs),                \n",
    "    dim = 32, # default                         \n",
    "    dim_out = 1,                       \n",
    "    depth = 6, # default                        \n",
    "    heads = 8, # default                         \n",
    "    attn_dropout = 0.1, # default              \n",
    "    ff_dropout = 0.1, # default                  \n",
    "    mlp_hidden_mults = (4, 2),       \n",
    "    cont_embeddings = 'MLP', # default \n",
    "    attentiontype = 'colrow', # default \n",
    "    final_mlp_style = 'sep', # default\n",
    "    y_dim = 1 # porque es regression \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "label_map = {\"train\": 0, \"valid\": 1, \"test\": 2}\n",
    "kk = np.random.choice([\"train\", \"valid\", \"test\"], p = [0.65, 0.15, 0.2], size=(X.shape[0],))\n",
    "np_set_array_mapped = np.vectorize(label_map.get)(kk)\n",
    "torch_set_tensor = torch.from_numpy(np_set_array_mapped).long()\n",
    "torch_set_tensor = torch_set_tensor.unsqueeze(1)  \n",
    "X_with_set = torch.cat((X, torch_set_tensor), dim=1)\n",
    "\n",
    "train_mask = X_with_set[:, -1] == 0\n",
    "train_indices = torch.nonzero(train_mask).squeeze()\n",
    "print(\"train indices\", train_indices)\n",
    "\n",
    "valid_mask = X_with_set[:, -1] == 1\n",
    "valid_indices = torch.nonzero(valid_mask).squeeze()\n",
    "print(\"valid indices\", valid_indices)\n",
    "\n",
    "test_mask = X_with_set[:, -1] == 2\n",
    "test_indices = torch.nonzero(test_mask).squeeze()\n",
    "print(\"test indices\", test_indices)\n",
    "\n",
    "nan_mask = torch.isnan(X)\n",
    "nan_mask_y = torch.isnan(y)\n",
    "\n",
    "\n",
    "X_train = {\n",
    "    'data': X[train_indices],\n",
    "    'mask': X[nan_mask] \n",
    "}\n",
    "# if X_train['data'].shape != X_train['mask'].shape:\n",
    "#     raise'Shape of data not same as that of nan mask!'\n",
    "    \n",
    "X_valid = {\n",
    "    'data': X[valid_indices],\n",
    "    'mask': X[nan_mask] \n",
    "}\n",
    "# if X_valid['data'].shape != X_valid['mask'].shape:\n",
    "#     raise'Shape of data not same as that of nan mask!'\n",
    "\n",
    "X_test = {\n",
    "    'data': X[test_indices],\n",
    "    'mask': X[nan_mask] \n",
    "}\n",
    "# if X_test['data'].shape != X_test['mask'].shape:\n",
    "#     raise'Shape of data not same as that of nan mask!'\n",
    "        \n",
    "y_train = {\n",
    "    'data': y[train_indices].reshape(-1, 1)\n",
    "} \n",
    "\n",
    "y_valid = {\n",
    "    'data': y[valid_indices].reshape(-1, 1)\n",
    "} \n",
    "\n",
    "y_test = {\n",
    "    'data': y[test_indices].reshape(-1, 1)\n",
    "} \n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "cont = torch.index_select(X_train['data'], 1, torch.tensor(con_idxs))\n",
    "\n",
    "train_mean = torch.mean(cont, dim=0)\n",
    "train_std = torch.std(cont, dim=0)\n",
    "\n",
    "continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32) \n",
    "\n",
    "train_ds = DataSetCatCon(X_train, y_train, cat_idxs,'reg',continuous_mean_std)\n",
    "trainloader = DataLoader(train_ds, batch_size=256, shuffle=True,num_workers=4)\n",
    "\n",
    "# valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs,'reg', continuous_mean_std)\n",
    "# validloader = DataLoader(valid_ds, batch_size=256, shuffle=False,num_workers=4)\n",
    "\n",
    "# test_ds = DataSetCatCon(X_test, y_test, cat_idxs,'reg', continuous_mean_std)\n",
    "# testloader = DataLoader(test_ds, batch_size=256, shuffle=False,num_workers=4)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device is {device}.\")\n",
    "\n",
    "vision_dset = 'store_true'\n",
    "scheduler = 'cosine' # default \n",
    "\n",
    "# for epoch in range(100):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(trainloader, 0):\n",
    "#         optimizer.zero_grad()\n",
    "#         x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
    "#         _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model,vision_dset)           \n",
    "#         reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "#         y_reps = reps[:,0,:]\n",
    "#         y_outs = model.mlpfory(y_reps)\n",
    "#         loss = criterion(y_outs,y_gts) \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "#         running_loss += loss.item()\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         valid_rmse = mean_sq_error(model, validloader, device,vision_dset)    \n",
    "#         test_rmse = mean_sq_error(model, testloader, device,vision_dset)  \n",
    "#         print('[EPOCH %d] VALID RMSE: %.3f' %\n",
    "#             (epoch + 1, valid_rmse ))\n",
    "#         print('[EPOCH %d] TEST RMSE: %.3f' %\n",
    "#             (epoch + 1, test_rmse ))\n",
    "#     model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "034b65ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328.1820</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433.2234</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>296.1394</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322.0481</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>448.1802</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>322.0481</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>509.1676</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>311.1754</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0             1             2             3             4    \\\n",
       "0  328.1820  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1  433.2234  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "2  296.1394  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3  322.0481 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09   \n",
       "4  448.1802  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "5  322.0481 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09   \n",
       "6  509.1676  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "7  311.1754  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            5             6             7             8             9    ...  \\\n",
       "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "1  0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  ...   \n",
       "2  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "3 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09  ...   \n",
       "4  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "5 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09  ...   \n",
       "6  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "7  0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  ...   \n",
       "\n",
       "            91            92            93            94            95   \\\n",
       "0  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  1.000000e+00   \n",
       "1  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  1.000000e+00   \n",
       "2  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09   \n",
       "4  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "5 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09   \n",
       "6  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "7  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  1.000000e+00   \n",
       "\n",
       "            96            97            98            99            100  \n",
       "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "1  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "2  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "3 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09  \n",
       "4  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "5 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09 -2.147484e+09  \n",
       "6  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "7  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "\n",
       "[8 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).copy()\n",
    "# pd.DataFrame(X_train['data']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b6dc6-86f9-47e8-95be-9bc25311ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2218, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f09155-873b-4858-ba4d-e7b845d96b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class MyDataModule(d2l.DataModule):\n",
    "    def __init__(self, X, y, p_train=0.7): # training data: 70% of dataset\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
    "        #tensors = tuple(a[indices] for a in tensors)\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        return torch.utils.data.DataLoader(dataset, shuffle=train)\n",
    "    \n",
    "    def get_dataloader(self, train):\n",
    "        i = slice(0, self.p_train*len(self.X)) if train else slice(self.p_train*len(self.X), None)\n",
    "        return self.get_tensorloader((self.X, self.y), train, i)\n",
    "\n",
    "\n",
    "class LinearRegressionScratch(d2l.Module):  #@save\n",
    "    \"\"\"The linear regression model implemented from scratch.\"\"\"\n",
    "    def __init__(self, num_inputs, lr, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.w = torch.normal(0, sigma, (num_inputs, 1), requires_grad=True)\n",
    "        self.b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return torch.matmul(X.double(), self.w.double()) + self.b.double()\n",
    "\n",
    "    def loss(self, y_hat, y):\n",
    "        l = (y_hat - y) ** 2 / 2\n",
    "        return l.mean()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return SGD([self.w, self.b], self.lr)\n",
    "\n",
    "\n",
    "class SGD(d2l.HyperParameters):  #@save\n",
    "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
    "    def __init__(self, params, lr):\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param -= self.lr * param.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()\n",
    "\n",
    "\n",
    "my_data = MyDataModule(X, y)\n",
    "model = LinearRegressionScratch(X.shape[1], lr=0.001)\n",
    "trainer = d2l.Trainer(max_epochs=3)\n",
    "trainer.fit(model, my_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
