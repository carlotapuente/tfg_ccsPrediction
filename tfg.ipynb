{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d36739ee-a766-4591-9154-1ec49fb3f65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.0.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision==0.15.1 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch==2.0.0) (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torchvision==0.15.1) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torchvision==0.15.1) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torchvision==0.15.1) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.1) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.0.0 torchvision==0.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729565be-5bab-45de-b2fb-df4bac1f3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install d2l==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ec93e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Molecule Name Molecular Formula  \\\n",
      "0   3-[3-(2,3-dihydroindol-1-yl)propyl]-1-[(4-fluo...        C19H22FN3O   \n",
      "1   3-{[1,1'-biphenyl]-4-ylmethylidene}-6-fluoro-2...        C22H15FO3S   \n",
      "2   1-{[3-(4-methoxyphenyl)-1,2,4-oxadiazol-5-yl]m...        C25H28N4O3   \n",
      "3   3-[2-oxo-2-(4-phenylmethanesulfonylpiperazin-1...       C22H30N4O5S   \n",
      "4   2-{[1,1'-biphenyl]-2-ylamino}-1-(morpholin-4-y...        C18H20N2O2   \n",
      "5   1-(2-{[1,1'-biphenyl]-2-ylamino}acetyl)imidazo...        C17H17N3O2   \n",
      "6   N-(2,3-dihydro-1,4-benzodioxin-6-yl)-2-{[1-(4-...      C23H21N5O3S2   \n",
      "7                                              Tm_322                     \n",
      "8   N-[(1-benzyl-3,5-dimethylpyrazol-4-yl)methyl]-...       C24H25N5O2S   \n",
      "9   N-{[1,1'-biphenyl]-4-yl}-2-(2-oxoquinoxalin-1-...        C22H17N3O2   \n",
      "10                                             Tm_322                     \n",
      "11  N-(4-ethoxyphenyl)-2-{2-[5-(4-methylphenyl)-1,...        C25H24N6O3   \n",
      "12                                             Tm_622                     \n",
      "14  N-cyclohexyl-N-ethyl-4-(piperidine-1-sulfonyl)...      C19H30N2O4S2   \n",
      "15  [(6-amino-1-benzyl-2,4-dioxo-3H-pyrimidin-5-yl...       C25H26N4O7S   \n",
      "16  3-[(2H-1,3-benzodioxol-5-ylmethyl)sulfanyl]-4-...       C21H17N3O3S   \n",
      "17  N-[(1S)-1-(1H-1,3-benzodiazol-2-yl)-2-phenylet...      C26H28N4O3S2   \n",
      "18    4-methoxy-N-[4-(piperidin-1-yl)phenyl]benzamide        C19H22N2O2   \n",
      "19  1-[4-(4-isopropylbenzoyl)piperazin-1-yl]-3-phe...        C23H26N2O2   \n",
      "21                                       Fenamic acid         C13H11NO2   \n",
      "22  2-{[5-(2H-1,3-benzodioxol-5-yl)-4-phenyl-1,2,4...      C28H27N5O5S2   \n",
      "23  5-(2-{[5-(4-fluorophenyl)-4-(oxolan-2-ylmethyl...      C25H26FN5O3S   \n",
      "24  4-(4-chlorobenzenesulfonyl)-5-{[(2-fluoropheny...    C20H13ClFNO4S2   \n",
      "25  3-({[2-(morpholin-4-ylmethyl)-5-phenylthieno[2...       C25H22N4OS2   \n",
      "26  (4-bromophenyl)methyl 4-(pyrrolidine-1-sulfony...      C18H18BrNO4S   \n",
      "27  1-(2,3-dihydro-1,4-benzodioxin-6-yl)-2-({5-phe...       C22H16N2O4S   \n",
      "28  N-(5-chloro-2-fluorophenyl)-3-(furan-2-yl)-2-(...     C20H13ClFN5O2   \n",
      "29  1-[3-(2-benzylpyrrolidine-1-carbonyl)benzenesu...       C28H31N3O3S   \n",
      "\n",
      "    METLIN ID Precursor Adduct    CCS1    CCS2    CCS3  CCS_AVG  % CV  \\\n",
      "0   1181481.0    328.1820[M+H]  176.63  176.63  176.63   176.63     0   \n",
      "1   1191359.0    379.0799[M+H]  192.26  192.26  192.26   192.26     0   \n",
      "2   1228206.0    433.2234[M+H]  211.12  211.12  211.12   211.12     0   \n",
      "3   1176932.0    463.2010[M+H]  204.22  204.22  204.22   204.22     0   \n",
      "4   1183857.0    297.1598[M+H]  174.47  174.47  174.47   174.47     0   \n",
      "5   1177044.0    296.1394[M+H]  170.17  170.17  170.17   170.17     0   \n",
      "6   1184006.0    480.1159[M+H]  215.24  215.24  215.24   215.24     0   \n",
      "7         NaN    322.0481[M+H]  154.22  154.22  154.22   154.22     0   \n",
      "8   1205024.0    448.1802[M+H]  198.49  198.49  198.49   198.49     0   \n",
      "9   1184329.0    356.1394[M+H]  195.75  195.75  195.75   195.75     0   \n",
      "10        NaN    322.0481[M+H]  154.81  154.81  154.81   154.81     0   \n",
      "11  1226735.0    457.1983[M+H]  214.97  214.97  214.97   214.97     0   \n",
      "12        NaN    622.0290[M+H]  205.00  205.00  205.00   205.00     0   \n",
      "14  1202359.0    415.1720[M+H]  204.53  204.53  204.53   204.53     0   \n",
      "15  1184004.0    527.1595[M+H]  211.86  211.86  211.86   211.86     0   \n",
      "16  1198192.0    392.1063[M+H]  189.34  189.34  189.34   189.34     0   \n",
      "17  1174820.0    509.1676[M+H]  214.83  214.83  214.83   214.83     0   \n",
      "18  1177187.0    311.1754[M+H]  185.40  185.40  185.40   185.40     0   \n",
      "19  1172634.0    363.2067[M+H]  202.66  202.66  202.66   202.66     0   \n",
      "21    69644.0    214.0863[M+H]  145.32  145.32  145.32   145.32     0   \n",
      "22  1197809.0    578.1526[M+H]  228.78  228.78  228.78   228.78     0   \n",
      "23  1195557.0    496.1813[M+H]  211.09  211.09  211.09   211.09     0   \n",
      "24  1195704.0    450.0031[M+H]  192.54  192.54  192.54   192.54     0   \n",
      "25  1198196.0    459.1308[M+H]  209.26  209.26  209.26   209.26     0   \n",
      "26  1207451.0    424.0213[M+H]  201.34  201.34  201.34   201.34     0   \n",
      "27  1196119.0    405.0904[M+H]  202.59  202.59  202.59   202.59     0   \n",
      "28  1191482.0    410.0815[M+H]  196.36  196.36  196.36   196.36     0   \n",
      "29  1222446.0    490.2159[M+H]  210.78  210.78  210.78   210.78     0   \n",
      "\n",
      "         m/z  ... V2205  V2206  V2207 V2208  V2209  V2210  V2211 V2212 V2213  \\\n",
      "0   328.1820  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "1   379.0799  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0   \n",
      "2   433.2234  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "3   463.2010  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "4   297.1598  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "5   296.1394  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "6   480.1159  ...   0.0    0.0    0.0   1.0    0.0    0.0    0.0   0.0   1.0   \n",
      "7   322.0481  ...   NaN    NaN    NaN   NaN    NaN    NaN    NaN   NaN   NaN   \n",
      "8   448.1802  ...   0.0    0.0    0.0   1.0    0.0    0.0    0.0   0.0   1.0   \n",
      "9   356.1394  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "10  322.0481  ...   NaN    NaN    NaN   NaN    NaN    NaN    NaN   NaN   NaN   \n",
      "11  457.1983  ...   0.0    0.0    0.0   0.0    1.0    0.0    0.0   0.0   1.0   \n",
      "12  622.0290  ...   NaN    NaN    NaN   NaN    NaN    NaN    NaN   NaN   NaN   \n",
      "14  415.1720  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "15  527.1595  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "16  392.1063  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0   \n",
      "17  509.1676  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "18  311.1754  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "19  363.2067  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "21  214.0863  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0   \n",
      "22  578.1526  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "23  496.1813  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "24  450.0031  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0   \n",
      "25  459.1308  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "26  424.0213  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "27  405.0904  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0   \n",
      "28  410.0815  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   1.0   \n",
      "29  490.2159  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0   0.0   1.0   \n",
      "\n",
      "   V2214  \n",
      "0    0.0  \n",
      "1    0.0  \n",
      "2    1.0  \n",
      "3    0.0  \n",
      "4    0.0  \n",
      "5    0.0  \n",
      "6    1.0  \n",
      "7    NaN  \n",
      "8    1.0  \n",
      "9    0.0  \n",
      "10   NaN  \n",
      "11   1.0  \n",
      "12   NaN  \n",
      "14   0.0  \n",
      "15   0.0  \n",
      "16   1.0  \n",
      "17   1.0  \n",
      "18   0.0  \n",
      "19   0.0  \n",
      "21   0.0  \n",
      "22   1.0  \n",
      "23   1.0  \n",
      "24   1.0  \n",
      "25   1.0  \n",
      "26   0.0  \n",
      "27   1.0  \n",
      "28   0.0  \n",
      "29   0.0  \n",
      "\n",
      "[28 rows x 2235 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = 'METLIN_CCS_vectorfingerprintsVectorized.csv'\n",
    "\n",
    "column_name = 'Dimer.1'\n",
    "value_to_filter = 'Monomer'\n",
    "\n",
    "original_data = pd.read_csv(csv_file_path, nrows = 0)\n",
    "\n",
    "data = original_data[original_data['Dimer.1'] == 'Monomer']\n",
    "\n",
    "# Save the filtered DataFrame back to the CSV file, overwriting the original file\n",
    "data.to_csv('METLIN_CCS_vectorfingerprintsVectorized_filtered.csv', index=False)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d342aae-c875-435b-bd3d-e00fbfa44d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [2.]\n",
      " [0.]]\n",
      "0     [1.0]\n",
      "1     [1.0]\n",
      "2     [1.0]\n",
      "3     [1.0]\n",
      "4     [1.0]\n",
      "5     [1.0]\n",
      "6     [1.0]\n",
      "7     [1.0]\n",
      "8     [1.0]\n",
      "9     [1.0]\n",
      "10    [1.0]\n",
      "11    [1.0]\n",
      "12    [1.0]\n",
      "14    [1.0]\n",
      "15    [1.0]\n",
      "16    [1.0]\n",
      "17    [1.0]\n",
      "18    [1.0]\n",
      "19    [1.0]\n",
      "21    [1.0]\n",
      "22    [1.0]\n",
      "23    [1.0]\n",
      "24    [1.0]\n",
      "25    [1.0]\n",
      "26    [1.0]\n",
      "27    [1.0]\n",
      "28    [1.0]\n",
      "29    [1.0]\n",
      "Name: Adduct, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "adducts = data.iloc[:, 10]\n",
    "adduct_types = ['[M+H]', '[M+Na]', '[2M+H]']\n",
    "encoder = OrdinalEncoder()\n",
    "adducts_2d = np.array(adduct_types).reshape(-1, 1)\n",
    "encoded_adducts = encoder.fit_transform(adducts_2d)\n",
    "print(encoded_adducts)\n",
    "\n",
    "adducts_map = {'[M+H]': encoded_adducts[0], '[M+Na]': encoded_adducts[1], '[2M+H]': encoded_adducts[2]}\n",
    "mapped_adducts = adducts.map(adducts_map)\n",
    "print(mapped_adducts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "228fe820-2eb2-4e4e-b3f1-620e1a4246b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 100])\n",
      "tensor([[328.1820,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [379.0799,   1.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [433.2234,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        ...,\n",
      "        [405.0904,   1.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [410.0815,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [490.2159,   1.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# adduct = torch.tensor(mapped_adducts)\n",
    "fingerprints = torch.tensor(data.iloc[:, 21:121].to_numpy(dtype=int))\n",
    "# fingerprints = data.iloc[:, 21:121]\n",
    "print(fingerprints.shape)\n",
    "# fingerprints = torch.tensor(data.iloc[:, 21:2235].to_numpy(dtype=int))\n",
    "mz = torch.tensor(data.iloc[:, 9].to_numpy(dtype=float))\n",
    "# mz = data.iloc[:, 9]\n",
    " \n",
    "# dataset_tensor = X    \n",
    "# X = torch.cat((mz.unsqueeze(1), fingerprints, adduct), dim=1) \n",
    "X = torch.cat((mz.unsqueeze(1), fingerprints), dim=1)\n",
    "# fingerprints.insert(0, 'm/z', mz)\n",
    "# fingerprints['mz'] = mz\n",
    "# X = fingerprints\n",
    "\n",
    "# X = data.iloc[:, 21:121]\n",
    "# mz.unsqueeze convierte el vector mz de dimension [100] en una matriz de dimensiones [100,1], para poder concatenarlo\n",
    "\n",
    "# target = y\n",
    "y = torch.tensor(data.iloc[:, 7].to_numpy(dtype=float))\n",
    "# y = data.iloc[:, 7].to_numpy()\n",
    "\n",
    "print(X)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Display the name of the active environment\n",
    "print(f\"Active environment: {os.environ['CONDA_DEFAULT_ENV']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49de8157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train indices tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12, 13, 18, 19, 20, 22, 23, 24, 25,\n",
      "        26])\n",
      "valid indices tensor([ 5,  9, 21, 27])\n",
      "test indices tensor([ 6, 14, 15, 16, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_10360\\416582879.py:92: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32)\n",
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_10360\\416582879.py:92: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 94\u001b[0m\n\u001b[0;32m     90\u001b[0m train_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstd(cont, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m continuous_mean_std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([train_mean,train_std])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \n\u001b[1;32m---> 94\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m DataSetCatCon(X_train, y_train, cat_idxs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg\u001b[39m\u001b[38;5;124m'\u001b[39m,continuous_mean_std)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# trainloader = DataLoader(train_ds, batch_size=256, shuffle=True,num_workers=4)\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs,'reg', continuous_mean_std)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# test_ds = DataSetCatCon(X_test, y_test, cat_idxs,'reg', continuous_mean_std)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# testloader = DataLoader(test_ds, batch_size=256, shuffle=False,num_workers=4)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\data_openml.py:110\u001b[0m, in \u001b[0;36mDataSetCatCon.__init__\u001b[1;34m(self, X, Y, cat_cols, task, continuous_mean_std)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, cat_cols,task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m,continuous_mean_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    109\u001b[0m     cat_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(cat_cols)\n\u001b[1;32m--> 110\u001b[0m     X_mask \u001b[38;5;241m=\u001b[39m  X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    111\u001b[0m     X \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    112\u001b[0m     con_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(cat_cols))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "from models import SAINT\n",
    "from data_openml import data_prep_openml,task_dset_ids,DataSetCatCon, data_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from augmentations import embed_data_mask\n",
    "\n",
    "\n",
    "categorical_indicator = [False] + [True] * 100 # faltan los adducts\n",
    "cat_dims = [2] * 100 # 2: fingerprints solo pueden tomar dos valores (binario)\n",
    "cat_dims = np.append(np.array([1]),np.array(cat_dims)).astype(int) #Appending 1 for CLS token, this is later used to generate embeddings.\n",
    "  \n",
    "cat_idxs = list(np.where(np.array(categorical_indicator)==True)[0]) # discrete/categorical features\n",
    "con_idxs = list(set(range(X.size(1))) - set(cat_idxs)) # continuous/numerical features \n",
    "\n",
    "model = SAINT(\n",
    "    categories = tuple(cat_dims), \n",
    "    num_continuous = len(con_idxs),                \n",
    "    dim = 32, # default                         \n",
    "    dim_out = 1,                       \n",
    "    depth = 6, # default                        \n",
    "    heads = 8, # default                         \n",
    "    attn_dropout = 0.1, # default              \n",
    "    ff_dropout = 0.1, # default                  \n",
    "    mlp_hidden_mults = (4, 2),       \n",
    "    cont_embeddings = 'MLP', # default \n",
    "    attentiontype = 'colrow', # default \n",
    "    final_mlp_style = 'sep', # default\n",
    "    y_dim = 1 # porque es regression \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "label_map = {\"train\": 0, \"valid\": 1, \"test\": 2}\n",
    "kk = np.random.choice([\"train\", \"valid\", \"test\"], p = [0.65, 0.15, 0.2], size=(X.shape[0],))\n",
    "np_set_array_mapped = np.vectorize(label_map.get)(kk)\n",
    "torch_set_tensor = torch.from_numpy(np_set_array_mapped).long()\n",
    "torch_set_tensor = torch_set_tensor.unsqueeze(1)  \n",
    "X_with_set = torch.cat((X, torch_set_tensor), dim=1)\n",
    "\n",
    "train_mask = X_with_set[:, -1] == 0\n",
    "train_indices = torch.nonzero(train_mask).squeeze()\n",
    "print(\"train indices\", train_indices)\n",
    "\n",
    "valid_mask = X_with_set[:, -1] == 1\n",
    "valid_indices = torch.nonzero(valid_mask).squeeze()\n",
    "print(\"valid indices\", valid_indices)\n",
    "\n",
    "test_mask = X_with_set[:, -1] == 2\n",
    "test_indices = torch.nonzero(test_mask).squeeze()\n",
    "print(\"test indices\", test_indices)\n",
    "\n",
    "nan_mask = torch.isnan(X)\n",
    "nan_mask_y = torch.isnan(y)\n",
    "\n",
    "\n",
    "X_train = {\n",
    "    'data': X[train_indices],\n",
    "    'mask': X[nan_mask] \n",
    "}\n",
    "X_valid = {\n",
    "    'data': X[valid_indices],\n",
    "    'mask': X[nan_mask] \n",
    "}\n",
    "X_test = {\n",
    "    'data': X[test_indices],\n",
    "    'mask': X[nan_mask] \n",
    "}\n",
    "\n",
    "y_train = {\n",
    "    'data': y[train_indices],\n",
    "    'mask': y[nan_mask_y] \n",
    "}\n",
    "y_valid = {\n",
    "    'data': y[valid_indices],\n",
    "    'mask': y[nan_mask_y] \n",
    "}\n",
    "y_test = {\n",
    "    'data': y[test_indices],\n",
    "    'mask': y[nan_mask_y] \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "cont = torch.index_select(X_train['data'], 1, torch.tensor(con_idxs))\n",
    "\n",
    "train_mean = torch.mean(cont, dim=0)\n",
    "train_std = torch.std(cont, dim=0)\n",
    "\n",
    "continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32) \n",
    "\n",
    "train_ds = DataSetCatCon(X_train, y_train, cat_idxs,'reg',continuous_mean_std)\n",
    "# trainloader = DataLoader(train_ds, batch_size=256, shuffle=True,num_workers=4)\n",
    "\n",
    "# valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs,'reg', continuous_mean_std)\n",
    "# validloader = DataLoader(valid_ds, batch_size=256, shuffle=False,num_workers=4)\n",
    "\n",
    "# test_ds = DataSetCatCon(X_test, y_test, cat_idxs,'reg', continuous_mean_std)\n",
    "# testloader = DataLoader(test_ds, batch_size=256, shuffle=False,num_workers=4)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device is {device}.\")\n",
    "\n",
    "vision_dset = 'store_true'\n",
    "scheduler = 'cosine' # default \n",
    "\n",
    "# for epoch in range(100):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(trainloader, 0):\n",
    "#         optimizer.zero_grad()\n",
    "#         x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
    "#         _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model,vision_dset)           \n",
    "#         reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "#         y_reps = reps[:,0,:]\n",
    "#         y_outs = model.mlpfory(y_reps)\n",
    "#         loss = criterion(y_outs,y_gts) \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "#         running_loss += loss.item()\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         valid_rmse = mean_sq_error(model, validloader, device,vision_dset)    \n",
    "#         test_rmse = mean_sq_error(model, testloader, device,vision_dset)  \n",
    "#         print('[EPOCH %d] VALID RMSE: %.3f' %\n",
    "#             (epoch + 1, valid_rmse ))\n",
    "#         print('[EPOCH %d] TEST RMSE: %.3f' %\n",
    "#             (epoch + 1, test_rmse ))\n",
    "#     model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b6dc6-86f9-47e8-95be-9bc25311ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2218, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f09155-873b-4858-ba4d-e7b845d96b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class MyDataModule(d2l.DataModule):\n",
    "    def __init__(self, X, y, p_train=0.7): # training data: 70% of dataset\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
    "        #tensors = tuple(a[indices] for a in tensors)\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        return torch.utils.data.DataLoader(dataset, shuffle=train)\n",
    "    \n",
    "    def get_dataloader(self, train):\n",
    "        i = slice(0, self.p_train*len(self.X)) if train else slice(self.p_train*len(self.X), None)\n",
    "        return self.get_tensorloader((self.X, self.y), train, i)\n",
    "\n",
    "\n",
    "class LinearRegressionScratch(d2l.Module):  #@save\n",
    "    \"\"\"The linear regression model implemented from scratch.\"\"\"\n",
    "    def __init__(self, num_inputs, lr, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.w = torch.normal(0, sigma, (num_inputs, 1), requires_grad=True)\n",
    "        self.b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return torch.matmul(X.double(), self.w.double()) + self.b.double()\n",
    "\n",
    "    def loss(self, y_hat, y):\n",
    "        l = (y_hat - y) ** 2 / 2\n",
    "        return l.mean()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return SGD([self.w, self.b], self.lr)\n",
    "\n",
    "\n",
    "class SGD(d2l.HyperParameters):  #@save\n",
    "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
    "    def __init__(self, params, lr):\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param -= self.lr * param.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()\n",
    "\n",
    "\n",
    "my_data = MyDataModule(X, y)\n",
    "model = LinearRegressionScratch(X.shape[1], lr=0.001)\n",
    "trainer = d2l.Trainer(max_epochs=3)\n",
    "trainer.fit(model, my_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
