{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1766b6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 12:04:53,267] A new study created in memory with name: no-name-ab60d3da-39a7-4cb4-900d-0075476bc5f1\n",
      "C:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (4, 2) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (8, 4) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (16, 8) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[W 2024-06-18 12:05:11,560] Trial 0 failed with parameters: {'dim': 25, 'depth': 2, 'heads': 7, 'attn_dropout': 0.7036589409961911, 'ff_dropout': 0.3780060235814118, 'mlp_hidden_mults': (8, 4), 'attentiontype': 'attn', 'final_mlp_style': 'sep', 'lr': 5.921246147494983e-05} because of the following error: AttributeError(\"'SAINT' object has no attribute 'transformer'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_22716\\2967713645.py\", line 36, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, testloader), n_trials=100)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\carlo\\train.py\", line 97, in objective\n",
      "    valid_rmse, test_rmse = train(model, optimizer, scheduler, epochs, trainloader, validloader, testloader)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\carlo\\train.py\", line 30, in train\n",
      "    reps = model.transformer(x_categ_enc, x_cont_enc)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1614, in __getattr__\n",
      "    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "AttributeError: 'SAINT' object has no attribute 'transformer'\n",
      "[W 2024-06-18 12:05:11,568] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SAINT' object has no attribute 'transformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# select best hyperparameters\u001b[39;00m\n\u001b[0;32m     35\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study()\n\u001b[1;32m---> 36\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, testloader), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     37\u001b[0m optim_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params \n\u001b[0;32m     39\u001b[0m model \u001b[38;5;241m=\u001b[39m SAINT(\n\u001b[0;32m     40\u001b[0m     categories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(cat_dims), \n\u001b[0;32m     41\u001b[0m     num_continuous \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(con_idxs),                \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     y_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# porque es regression \u001b[39;00m\n\u001b[0;32m     53\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[0;32m     63\u001b[0m             study,\n\u001b[0;32m     64\u001b[0m             func,\n\u001b[0;32m     65\u001b[0m             n_trials,\n\u001b[0;32m     66\u001b[0m             timeout,\n\u001b[0;32m     67\u001b[0m             catch,\n\u001b[0;32m     68\u001b[0m             callbacks,\n\u001b[0;32m     69\u001b[0m             gc_after_trial,\n\u001b[0;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[1], line 36\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# select best hyperparameters\u001b[39;00m\n\u001b[0;32m     35\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study()\n\u001b[1;32m---> 36\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, testloader), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     37\u001b[0m optim_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params \n\u001b[0;32m     39\u001b[0m model \u001b[38;5;241m=\u001b[39m SAINT(\n\u001b[0;32m     40\u001b[0m     categories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(cat_dims), \n\u001b[0;32m     41\u001b[0m     num_continuous \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(con_idxs),                \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     y_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# porque es regression \u001b[39;00m\n\u001b[0;32m     53\u001b[0m )\n",
      "File \u001b[1;32m~\\train.py:97\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial, cat_dims, con_idxs, trainloader, validloader, testloader)\u001b[0m\n\u001b[0;32m     94\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m     95\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 97\u001b[0m valid_rmse, test_rmse \u001b[38;5;241m=\u001b[39m train(model, optimizer, scheduler, epochs, trainloader, validloader, testloader)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m valid_rmse, test_rmse\n",
      "File \u001b[1;32m~\\train.py:30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, scheduler, epochs, trainloader, valloader, testloader)\u001b[0m\n\u001b[0;32m     28\u001b[0m x_categ, x_cont, y_gts, cat_mask, con_mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),data[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),data[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),data[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     29\u001b[0m _ , x_categ_enc, x_cont_enc \u001b[38;5;241m=\u001b[39m embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model, vision_dset)           \n\u001b[1;32m---> 30\u001b[0m reps \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransformer(x_categ_enc, x_cont_enc)\n\u001b[0;32m     31\u001b[0m y_reps \u001b[38;5;241m=\u001b[39m reps[:,\u001b[38;5;241m0\u001b[39m,:]\n\u001b[0;32m     32\u001b[0m y_outs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmlpfory(y_reps)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SAINT' object has no attribute 'transformer'"
     ]
    }
   ],
   "source": [
    "from data import load_data, data_prep\n",
    "from train import train, plot_learning_curve, objective\n",
    "from data_openml import DataSetCatCon\n",
    "from torch.utils.data import DataLoader\n",
    "from models import SAINT\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "\n",
    "\n",
    "X1, y = load_data(1000, 500)\n",
    "\n",
    "# select best fingerprints \n",
    "fgpts = X1.iloc[:, 2:-1]\n",
    "model2 = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, verbose=0)\n",
    "model2.fit(fgpts, y)\n",
    "fgpts_selector = SelectFromModel(model2, prefit=True, threshold=\"mean\", max_features=100)\n",
    "X = pd.concat([X1.iloc[:, :2], X1.loc[:, fgpts.columns[fgpts_selector.get_support()]]], axis=1)\n",
    "\n",
    "cat_dims, cat_idxs, con_idxs, X_train, y_train, X_valid, y_valid, X_test, y_test, train_mean, train_std, continuous_mean_std = data_prep(X, y, datasplit=[.65, .15, .2])\n",
    "\n",
    "train_ds = DataSetCatCon(X_train, y_train, cat_idxs,'reg',continuous_mean_std)\n",
    "trainloader = DataLoader(train_ds, batch_size=256, shuffle=True,num_workers=4)\n",
    "\n",
    "valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs,'reg', continuous_mean_std)\n",
    "validloader = DataLoader(valid_ds, batch_size=256, shuffle=False,num_workers=4)\n",
    "\n",
    "test_ds = DataSetCatCon(X_test, y_test, cat_idxs,'reg', continuous_mean_std)\n",
    "testloader = DataLoader(test_ds, batch_size=256, shuffle=False,num_workers=4)\n",
    "\n",
    "# select best hyperparameters\n",
    "study = optuna.create_study()\n",
    "study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, testloader), n_trials=100)\n",
    "optim_params = study.best_params \n",
    "\n",
    "model = SAINT(\n",
    "    categories = tuple(cat_dims), \n",
    "    num_continuous = len(con_idxs),                \n",
    "    dim = optim_params['dim'],                         \n",
    "    dim_out = 1,                       \n",
    "    depth = optim_params['depth'],                        \n",
    "    heads = optim_params['heads'],                         \n",
    "    attn_dropout = optim_params['attn_dropout'],             \n",
    "    ff_dropout = optim_params['ff_dropout'],                  \n",
    "    mlp_hidden_mults = optim_params['mlp_hidden_mults'],       \n",
    "    cont_embeddings = 'MLP',\n",
    "    attentiontype = optim_params['attentiontype'],\n",
    "    final_mlp_style = optim_params['final_mlp_style'],\n",
    "    y_dim = 1 # porque es regression \n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(),lr=optim_params['lr'])\n",
    "scheduler = 'cosine' # default \n",
    "\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "valid_rmse, test_rmse = train(model, optimizer, scheduler, epochs, trainloader, validloader, testloader)\n",
    "\n",
    "plot_learning_curve(valid_rmse, test_rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
