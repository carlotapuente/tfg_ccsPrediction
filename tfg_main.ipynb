{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1766b6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data import load_data, data_prep\n",
    "from train import train, objective, build_hidden_mults\n",
    "from data_openml import DataSetCatCon\n",
    "from torch.utils.data import DataLoader\n",
    "from models import SAINT\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from catboost import CatBoostRegressor\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import numpy as np\n",
    "import torch\n",
    "from optuna.exceptions import TrialPruned\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "##################################\n",
    "MAX_FEATURES=180\n",
    "N_TRIALS= 20     \n",
    "N_ROWS = None    # Set to None to use all rows\n",
    "BS = 16\n",
    "##################################\n",
    "\n",
    "X, y = load_data(n_rows=N_ROWS)\n",
    "\n",
    "#========> Set a random seed for reproducibility\n",
    "np.random.seed(239048)\n",
    "cat_dims, cat_idxs, con_idxs, X_train, y_train, X_valid, y_valid, X_test, y_test, train_mean, train_std, continuous_mean_std = data_prep(X, y, datasplit=[.65, .15, .2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98c9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the following file exists.\n",
    "filename = f\"fgps_selector-{MAX_FEATURES}.pkl\"\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        fgpts_selector = pickle.load(f)\n",
    "else:\n",
    "    # select best fingerprints \n",
    "    X_catboost = pd.DataFrame(X_train[\"data\"])\n",
    "    categorical_columns = [X_catboost.columns[i] for i in cat_idxs]\n",
    "    for col in categorical_columns:\n",
    "        X_catboost[col] = X_catboost[col].astype(\"int\")\n",
    "    model2 = CatBoostRegressor(cat_features=cat_idxs) \n",
    "    #================> should use only train data to avoid data leakage\n",
    "    model2.fit(X_catboost, y_train[\"data\"])\n",
    "    #==================> To only select based on max_features, set threshold=-np.inf.\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html\n",
    "    fgpts_selector = SelectFromModel(model2, prefit=True, threshold=-np.inf, max_features=MAX_FEATURES)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(fgpts_selector, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8e12e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[1 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "features_mask = fgpts_selector.get_support()\n",
    "# Force that both m/z and adduct are always selected \n",
    "features_mask[0] = True\n",
    "features_mask[1] = True\n",
    "# Ensure m/z is always selected\n",
    "assert features_mask[0] == True\n",
    "# Ensure adduct is always selected\n",
    "assert features_mask[1] == True\n",
    "\n",
    "n_features = X_train[\"data\"][:, features_mask].shape[1]\n",
    "\n",
    "cat_idxs = list(range(1, n_features))\n",
    "print(cat_idxs)\n",
    "cat_dims = cat_dims[:n_features]\n",
    "print(cat_dims)\n",
    "\n",
    "X_train[\"data\"] = X_train[\"data\"][:, features_mask]\n",
    "X_train[\"mask\"] = X_train[\"mask\"][:, features_mask]\n",
    "X_valid[\"data\"] = X_valid[\"data\"][:, features_mask]\n",
    "X_valid[\"mask\"] = X_valid[\"mask\"][:, features_mask]\n",
    "X_test[\"data\"] = X_test[\"data\"][:, features_mask]\n",
    "X_test[\"mask\"] = X_test[\"mask\"][:, features_mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d848b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DataSetCatCon(X_train, y_train, cat_idxs,'reg',continuous_mean_std)\n",
    "trainloader = DataLoader(train_ds, batch_size=BS, shuffle=True,num_workers=4)\n",
    "\n",
    "valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs,'reg', continuous_mean_std)\n",
    "validloader = DataLoader(valid_ds, batch_size=BS, shuffle=False,num_workers=4)\n",
    "\n",
    "test_ds = DataSetCatCon(X_test, y_test, cat_idxs,'reg', continuous_mean_std)\n",
    "testloader = DataLoader(test_ds, batch_size=BS, shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a11c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-28 12:56:13,213] Using an existing study with name 'MF_180_step-1' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "# select best hyperparameters\n",
    "\n",
    "storage_name = \"sqlite:///saint.db\"\n",
    "study1 = optuna.create_study(study_name=f\"MF_{MAX_FEATURES}_step-1\", storage=storage_name, load_if_exists=True, pruner=optuna.pruners.NopPruner())\n",
    "\n",
    "already_done = len([trial for trial in study1.trials if trial.state == optuna.trial.TrialState.COMPLETE])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55cc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_to_do = N_TRIALS - already_done\n",
    "if n_trials_to_do > 0:\n",
    "    study1.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, first_trial=True), n_trials=n_trials_to_do, catch=(Exception, ))\n",
    "\n",
    "optim_params1 = study1.best_params \n",
    "\n",
    "lr = optim_params1['lr']\n",
    "wd = optim_params1['weight_decay']\n",
    "epochs = optim_params1['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0fa6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-28 12:56:13,397] A new study created in RDB with name: MF_180_id_6579809149785645258_step-2c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 45, depth: 1, heads: 7, attn_dropout: 0.22171703538357104, ff_dropout: 0.7955888435904183, mlp_hidden_mults: (4, 2), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 12:56:22,254] Trial 0 failed with parameters: {'dim': 45, 'depth': 1, 'heads': 7, 'attn_dropout': 0.22171703538357104, 'ff_dropout': 0.7955888435904183, 'mlp_hidden_mults': 4, 'final_mlp_style': 'sep'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 11.75 GiB total capacity; 9.18 GiB already allocated; 867.62 MiB free; 9.20 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 48, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/adamw.py\", line 93, in step\n",
      "    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 11.75 GiB total capacity; 9.18 GiB already allocated; 867.62 MiB free; 9.20 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 12:56:22,256] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 35, depth: 2, heads: 5, attn_dropout: 0.21459832928096959, ff_dropout: 0.16146670728870777, mlp_hidden_mults: (4, 2), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 12:56:29,155] Trial 1 failed with parameters: {'dim': 35, 'depth': 2, 'heads': 5, 'attn_dropout': 0.21459832928096959, 'ff_dropout': 0.16146670728870777, 'mlp_hidden_mults': 4, 'final_mlp_style': 'common'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 1.20 GiB (GPU 0; 11.75 GiB total capacity; 9.19 GiB already allocated; 130.75 MiB free; 9.95 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 48, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/adamw.py\", line 93, in step\n",
      "    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 1.20 GiB (GPU 0; 11.75 GiB total capacity; 9.19 GiB already allocated; 130.75 MiB free; 9.95 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 12:56:29,156] Trial 1 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 24, depth: 1, heads: 5, attn_dropout: 0.40415341749482925, ff_dropout: 0.40305917353179344, mlp_hidden_mults: (8, 4), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [19:19<00:00, 116.00s/it]\n",
      "[I 2024-06-28 13:15:51,122] Trial 2 finished with value: 17.284272956848145 and parameters: {'dim': 24, 'depth': 1, 'heads': 5, 'attn_dropout': 0.40415341749482925, 'ff_dropout': 0.40305917353179344, 'mlp_hidden_mults': 8, 'final_mlp_style': 'common'}. Best is trial 2 with value: 17.284272956848145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 57, depth: 1, heads: 8, attn_dropout: 0.8202072362401538, ff_dropout: 0.375388056793699, mlp_hidden_mults: (16, 8), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 13:16:03,446] Trial 3 failed with parameters: {'dim': 57, 'depth': 1, 'heads': 8, 'attn_dropout': 0.8202072362401538, 'ff_dropout': 0.375388056793699, 'mlp_hidden_mults': 16, 'final_mlp_style': 'sep'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 3.17 GiB (GPU 0; 11.75 GiB total capacity; 9.51 GiB already allocated; 716.00 MiB free; 9.54 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 47, in train\n",
      "    loss.backward()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/tensor.py\", line 245, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 145, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 3.17 GiB (GPU 0; 11.75 GiB total capacity; 9.51 GiB already allocated; 716.00 MiB free; 9.54 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 13:16:03,447] Trial 3 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 52, depth: 1, heads: 8, attn_dropout: 0.8370557256957373, ff_dropout: 0.6510743432523631, mlp_hidden_mults: (8, 4), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 13:16:12,468] Trial 4 failed with parameters: {'dim': 52, 'depth': 1, 'heads': 8, 'attn_dropout': 0.8370557256957373, 'ff_dropout': 0.6510743432523631, 'mlp_hidden_mults': 8, 'final_mlp_style': 'common'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.64 GiB (GPU 0; 11.75 GiB total capacity; 7.09 GiB already allocated; 2.29 GiB free; 7.95 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 47, in train\n",
      "    loss.backward()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/tensor.py\", line 245, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 145, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 2.64 GiB (GPU 0; 11.75 GiB total capacity; 7.09 GiB already allocated; 2.29 GiB free; 7.95 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 13:16:12,468] Trial 4 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 44, depth: 1, heads: 4, attn_dropout: 0.5102431475951822, ff_dropout: 0.8445386483478609, mlp_hidden_mults: (16, 8), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 13:16:20,022] Trial 5 failed with parameters: {'dim': 44, 'depth': 1, 'heads': 4, 'attn_dropout': 0.5102431475951822, 'ff_dropout': 0.8445386483478609, 'mlp_hidden_mults': 16, 'final_mlp_style': 'sep'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 1.89 GiB (GPU 0; 11.75 GiB total capacity; 9.49 GiB already allocated; 227.44 MiB free; 10.02 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 48, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/adamw.py\", line 93, in step\n",
      "    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 1.89 GiB (GPU 0; 11.75 GiB total capacity; 9.49 GiB already allocated; 227.44 MiB free; 10.02 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 13:16:20,023] Trial 5 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 44, depth: 1, heads: 5, attn_dropout: 0.5954818649615975, ff_dropout: 0.8131209799202824, mlp_hidden_mults: (16, 8), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 13:16:27,348] Trial 6 failed with parameters: {'dim': 44, 'depth': 1, 'heads': 5, 'attn_dropout': 0.5954818649615975, 'ff_dropout': 0.8131209799202824, 'mlp_hidden_mults': 16, 'final_mlp_style': 'common'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 1.89 GiB (GPU 0; 11.75 GiB total capacity; 7.62 GiB already allocated; 212.19 MiB free; 10.02 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 48, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/adamw.py\", line 91, in step\n",
      "    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 1.89 GiB (GPU 0; 11.75 GiB total capacity; 7.62 GiB already allocated; 212.19 MiB free; 10.02 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 13:16:27,349] Trial 6 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 24, depth: 2, heads: 5, attn_dropout: 0.7616334662203074, ff_dropout: 0.3812765630245043, mlp_hidden_mults: (16, 8), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [06:51<1:01:43, 411.50s/it]\n",
      "[I 2024-06-28 13:23:22,501] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 16, depth: 2, heads: 6, attn_dropout: 0.46516521858652504, ff_dropout: 0.3706044843550712, mlp_hidden_mults: (8, 4), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [19:59<00:00, 119.99s/it]\n",
      "[I 2024-06-28 13:43:24,066] Trial 8 finished with value: 16.738755416870116 and parameters: {'dim': 16, 'depth': 2, 'heads': 6, 'attn_dropout': 0.46516521858652504, 'ff_dropout': 0.3706044843550712, 'mlp_hidden_mults': 8, 'final_mlp_style': 'common'}. Best is trial 8 with value: 16.738755416870116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 54, depth: 1, heads: 8, attn_dropout: 0.43018470507516215, ff_dropout: 0.645025092966387, mlp_hidden_mults: (8, 4), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 13:43:33,523] Trial 9 failed with parameters: {'dim': 54, 'depth': 1, 'heads': 8, 'attn_dropout': 0.43018470507516215, 'ff_dropout': 0.645025092966387, 'mlp_hidden_mults': 8, 'final_mlp_style': 'sep'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.85 GiB (GPU 0; 11.75 GiB total capacity; 7.65 GiB already allocated; 1.97 GiB free; 8.13 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 47, in train\n",
      "    loss.backward()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/tensor.py\", line 245, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 145, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 2.85 GiB (GPU 0; 11.75 GiB total capacity; 7.65 GiB already allocated; 1.97 GiB free; 8.13 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 13:43:33,524] Trial 9 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 30, depth: 2, heads: 6, attn_dropout: 0.5342880651214797, ff_dropout: 0.5275458090085285, mlp_hidden_mults: (16, 8), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 13:43:39,180] Trial 10 failed with parameters: {'dim': 30, 'depth': 2, 'heads': 6, 'attn_dropout': 0.5342880651214797, 'ff_dropout': 0.5275458090085285, 'mlp_hidden_mults': 16, 'final_mlp_style': 'common'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 900.00 MiB (GPU 0; 11.75 GiB total capacity; 9.00 GiB already allocated; 671.69 MiB free; 9.44 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 48, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/adamw.py\", line 91, in step\n",
      "    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 900.00 MiB (GPU 0; 11.75 GiB total capacity; 9.00 GiB already allocated; 671.69 MiB free; 9.44 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 13:43:39,181] Trial 10 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 23, depth: 2, heads: 4, attn_dropout: 0.2819413093881771, ff_dropout: 0.13257030385772506, mlp_hidden_mults: (4, 2), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [32:04<00:00, 192.43s/it]\n",
      "[I 2024-06-28 14:15:46,441] Trial 11 finished with value: 16.96507873535156 and parameters: {'dim': 23, 'depth': 2, 'heads': 4, 'attn_dropout': 0.2819413093881771, 'ff_dropout': 0.13257030385772506, 'mlp_hidden_mults': 4, 'final_mlp_style': 'sep'}. Best is trial 8 with value: 16.738755416870116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 62, depth: 1, heads: 4, attn_dropout: 0.8738444420973446, ff_dropout: 0.4904913984236493, mlp_hidden_mults: (4, 2), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 14:15:58,100] Trial 12 failed with parameters: {'dim': 62, 'depth': 1, 'heads': 4, 'attn_dropout': 0.8738444420973446, 'ff_dropout': 0.4904913984236493, 'mlp_hidden_mults': 4, 'final_mlp_style': 'common'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 3.75 GiB (GPU 0; 11.75 GiB total capacity; 9.58 GiB already allocated; 572.75 MiB free; 9.73 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 47, in train\n",
      "    loss.backward()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/tensor.py\", line 245, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 145, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 3.75 GiB (GPU 0; 11.75 GiB total capacity; 9.58 GiB already allocated; 572.75 MiB free; 9.73 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 14:15:58,101] Trial 12 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 43, depth: 1, heads: 4, attn_dropout: 0.26456241205383113, ff_dropout: 0.6958103945048455, mlp_hidden_mults: (8, 4), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 14:16:04,179] Trial 13 failed with parameters: {'dim': 43, 'depth': 1, 'heads': 4, 'attn_dropout': 0.26456241205383113, 'ff_dropout': 0.6958103945048455, 'mlp_hidden_mults': 8, 'final_mlp_style': 'common'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 1.81 GiB (GPU 0; 11.75 GiB total capacity; 8.49 GiB already allocated; 1.12 GiB free; 9.16 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 48, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/adamw.py\", line 93, in step\n",
      "    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 1.81 GiB (GPU 0; 11.75 GiB total capacity; 8.49 GiB already allocated; 1.12 GiB free; 9.16 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 14:16:04,180] Trial 13 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 27, depth: 1, heads: 3, attn_dropout: 0.3222920202380187, ff_dropout: 0.8551979073315564, mlp_hidden_mults: (4, 2), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [22:15<02:28, 148.38s/it]\n",
      "[I 2024-06-28 14:38:21,914] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 50, depth: 1, heads: 2, attn_dropout: 0.49966539061443305, ff_dropout: 0.5534495065014647, mlp_hidden_mults: (4, 2), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 14:38:29,737] Trial 15 failed with parameters: {'dim': 50, 'depth': 1, 'heads': 2, 'attn_dropout': 0.49966539061443305, 'ff_dropout': 0.5534495065014647, 'mlp_hidden_mults': 4, 'final_mlp_style': 'sep'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.44 GiB (GPU 0; 11.75 GiB total capacity; 8.69 GiB already allocated; 1.15 GiB free; 9.16 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 48, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/adamw.py\", line 91, in step\n",
      "    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 2.44 GiB (GPU 0; 11.75 GiB total capacity; 8.69 GiB already allocated; 1.15 GiB free; 9.16 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 14:38:29,737] Trial 15 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 39, depth: 1, heads: 8, attn_dropout: 0.3515793605575398, ff_dropout: 0.5724657931708903, mlp_hidden_mults: (8, 4), final_mlp_style: common, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 14:38:34,849] Trial 16 failed with parameters: {'dim': 39, 'depth': 1, 'heads': 8, 'attn_dropout': 0.3515793605575398, 'ff_dropout': 0.5724657931708903, 'mlp_hidden_mults': 8, 'final_mlp_style': 'common'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 11.75 GiB total capacity; 7.11 GiB already allocated; 1.15 GiB free; 9.15 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 48, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/adamw.py\", line 93, in step\n",
      "    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 11.75 GiB total capacity; 7.11 GiB already allocated; 1.15 GiB free; 9.15 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 14:38:34,850] Trial 16 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 31, depth: 2, heads: 2, attn_dropout: 0.261202037248282, ff_dropout: 0.8790505891503672, mlp_hidden_mults: (4, 2), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 14:38:40,125] Trial 17 failed with parameters: {'dim': 31, 'depth': 2, 'heads': 2, 'attn_dropout': 0.261202037248282, 'ff_dropout': 0.8790505891503672, 'mlp_hidden_mults': 4, 'final_mlp_style': 'sep'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 962.00 MiB (GPU 0; 11.75 GiB total capacity; 9.97 GiB already allocated; 222.12 MiB free; 10.10 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 48, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/optim/adamw.py\", line 93, in step\n",
      "    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 962.00 MiB (GPU 0; 11.75 GiB total capacity; 9.97 GiB already allocated; 222.12 MiB free; 10.10 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 14:38:40,126] Trial 17 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 53, depth: 1, heads: 3, attn_dropout: 0.6701974708296727, ff_dropout: 0.3974650020829573, mlp_hidden_mults: (4, 2), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 14:38:48,654] Trial 18 failed with parameters: {'dim': 53, 'depth': 1, 'heads': 3, 'attn_dropout': 0.6701974708296727, 'ff_dropout': 0.3974650020829573, 'mlp_hidden_mults': 4, 'final_mlp_style': 'sep'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.74 GiB (GPU 0; 11.75 GiB total capacity; 7.01 GiB already allocated; 211.12 MiB free; 10.11 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 47, in train\n",
      "    loss.backward()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/tensor.py\", line 245, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 145, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 2.74 GiB (GPU 0; 11.75 GiB total capacity; 7.01 GiB already allocated; 211.12 MiB free; 10.11 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 14:38:48,655] Trial 18 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.613283190233199e-05, weight_decay: 0.04846185144056176, epochs: 10, dim: 48, depth: 2, heads: 2, attn_dropout: 0.7986870512655566, ff_dropout: 0.32132598306568055, mlp_hidden_mults: (4, 2), final_mlp_style: sep, optimizer: AdamW, scheduler: cosine\n",
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2024-06-28 14:39:00,480] Trial 19 failed with parameters: {'dim': 48, 'depth': 2, 'heads': 2, 'attn_dropout': 0.7986870512655566, 'ff_dropout': 0.32132598306568055, 'mlp_hidden_mults': 4, 'final_mlp_style': 'sep'} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.25 GiB (GPU 0; 11.75 GiB total capacity; 9.16 GiB already allocated; 263.12 MiB free; 10.06 GiB reserved in total by PyTorch)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_215226/2583905535.py\", line 15, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 175, in objective\n",
      "    valid_rmse = train(\n",
      "  File \"/home/carlota/repos/tfg_ccsPrediction/train.py\", line 47, in train\n",
      "    loss.backward()\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/tensor.py\", line 245, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/miniforge3/envs/ccs_pred/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 145, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 2.25 GiB (GPU 0; 11.75 GiB total capacity; 9.16 GiB already allocated; 263.12 MiB free; 10.06 GiB reserved in total by PyTorch)\n",
      "[W 2024-06-28 14:39:00,481] Trial 19 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "# Create an unique id for step-2 based on the best hyperparameters from step-1\n",
    "# unique_id = hash(\"{}-{}\".format(str(lr), str(wd), str(epochs)))\n",
    "\n",
    "unique_id = hash(\"{}-{}-{}\".format(str(lr), str(wd), str(epochs)))\n",
    "study = optuna.create_study(\n",
    "    study_name=f\"MF_{MAX_FEATURES}_id_{unique_id}_step-2c\",\n",
    "    storage=storage_name,\n",
    "    direction=\"minimize\",\n",
    "    pruner=optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1, max_resource=10, reduction_factor=3\n",
    "    ),\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "study.optimize(lambda trial: objective(trial, cat_dims, con_idxs, trainloader, validloader, lr=lr, wd=wd, epochs=epochs), n_trials=N_TRIALS, catch=(Exception, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f3846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [18:49<00:00, 112.90s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test RMSE: 16.95682563781738\n"
     ]
    }
   ],
   "source": [
    "optim_params = study.best_params \n",
    "optim_params['mlp_hidden_mults'] = build_hidden_mults(optim_params['mlp_hidden_mults'])  \n",
    "\n",
    "model = SAINT(\n",
    "    categories = tuple(cat_dims), \n",
    "    num_continuous = len(con_idxs),                \n",
    "    dim = optim_params['dim'],                         \n",
    "    dim_out = 1,                       \n",
    "    depth = optim_params['depth'],                        \n",
    "    heads = optim_params['heads'],                         \n",
    "    attn_dropout = optim_params['attn_dropout'],             \n",
    "    ff_dropout = optim_params['ff_dropout'],                  \n",
    "    mlp_hidden_mults = optim_params['mlp_hidden_mults'],       \n",
    "    cont_embeddings = 'MLP',\n",
    "    attentiontype = 'colrow',\n",
    "    final_mlp_style = optim_params['final_mlp_style'],\n",
    "    y_dim = 1 # porque es regression \n",
    ")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device = {device}\")\n",
    "model.to(device)\n",
    "\n",
    "# ========> we always use the following\n",
    "optimizer = optim.AdamW(model.parameters(),lr=optim_params1['lr'], weight_decay=optim_params1['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, optim_params1['epochs'])\n",
    "\n",
    "test_rmse = train(model, optimizer, scheduler, optim_params1[\"epochs\"], trainloader, testloader, plot=True)\n",
    "print(f\"Final test RMSE: {test_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
